{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_iris\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the iris data (150 observations, 4 predictors, 3 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (150, 4)\n",
      "y shape: (150,)\n"
     ]
    }
   ],
   "source": [
    "iris_data = load_iris()\n",
    "X = iris_data.data\n",
    "y = iris_data.target\n",
    "print(f'X shape: {X.shape}')\n",
    "print(f'y shape: {y.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y shape: (150, 3)\n"
     ]
    }
   ],
   "source": [
    "Y = to_categorical(y) # one-hot encode target labels\n",
    "print(f'Y shape: {Y.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and inspect the pre-trained weights and biases. Compare their shapes to the NN diagram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.load('data/weights.npy', allow_pickle=True)\n",
    "\n",
    "w1 = weights[0] # weights for hidden (1st) layer\n",
    "b1 = weights[1] # biases for hidden (1st) layer\n",
    "w2 = weights[2] # weights for output (2nd) layer\n",
    "b2 = weights[3] #biases for output (2nd) layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1 - shape: (4, 3)\n",
      "[[-0.42714605 -0.72814226  0.37730372]\n",
      " [ 0.39002347 -0.73936987  0.7850246 ]\n",
      " [ 0.12336338 -0.7267647  -0.48210236]\n",
      " [ 0.20957732 -0.7505736  -1.3789996 ]]\n",
      "\n",
      "b1 - shape: (3,)\n",
      "[0.         0.         0.31270522]\n",
      "\n",
      "w2 - shape: (3, 3)\n",
      "[[ 0.7043929   0.13273811 -0.845736  ]\n",
      " [-0.8318007  -0.6977086   0.75894   ]\n",
      " [ 1.1978723   0.14868832 -0.473792  ]]\n",
      "\n",
      "b2 - shape: (3,)\n",
      "[-1.2774311   0.45491916  0.73040146]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for arr, name in zip([w1,b1,w2,b2], ['w1','b1','w2','b2']):\n",
    "    print(f'{name} - shape: {arr.shape}')\n",
    "    print(arr)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first affine transformation we need to multiple the augmented input by the first weight matrix (i.e., layer).\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1 & X_{11} & X_{12} & X_{13} & X_{14}\\\\\n",
    "1 & X_{21} & X_{22} & X_{23} & X_{24}\\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "1 & X_{n1} & X_{n2} & X_{n3} & X_{n4}\\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "b_{1}^1 & b_{2}^1 & b_{3}^1\\\\\n",
    "W_{11}^1 & W_{12}^1 & W_{13}^1\\\\\n",
    "W_{21}^1 & W_{22}^1 & W_{23}^1\\\\\n",
    "W_{31}^1 & W_{32}^1 & W_{33}^1\\\\\n",
    "W_{41}^1 & W_{42}^1 & W_{43}^1\\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "z_{11}^1 & z_{12}^1 & z_{13}^1\\\\\n",
    "z_{21}^1 & z_{22}^1 & z_{23}^1\\\\\n",
    "\\vdots & \\vdots & \\vdots \\\\\n",
    "z_{n1}^1 & z_{n2}^1 & z_{n3}^1\\\\\n",
    "\\end{bmatrix}\n",
    "= \\textbf{Z}^1\n",
    "$$ \n",
    "<span style='color:gray'>About the notation: superscript refers to the layer and subscript refers to the index in the particular matrix. So $W_{23}^1$ is the weight in the 1st layer connecting the 2nd input to 3rd hidden node. Compare this matrix representation to the slide image. Also note the bias terms and ones that have been added to 'augment' certain matrices. You could consider $b_1^1$ to be $W_{01}^1$.</span><div></div>\n",
    "<span style='color:blue'>1. Augment X with a column of ones to create `X_aug`</span><div></div><span style='color:blue'>2. Create the first layer weight matrix `W1` by horizontally stacking the bias vector `b1`on top of `w1` (consult `add_ones_col` for ideas. Don't forget your `Tab` and `Shift+Tab` tricks!)</span><div></div><span style='color:blue'>3. Do the matrix multiplication to find `Z1`</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ones_col(X):\n",
    "    '''Augment matrix with a column of ones'''\n",
    "    X_aug = np.hstack((np.ones((X.shape[0],1)), X))\n",
    "    return X_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "X_aug = add_ones_col(X)\n",
    "W1 = np.vstack((weights[1], w1))\n",
    "Z1 = np.matmul(X_aug, W1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use our non-linarity\n",
    "$$\n",
    "\\textit{a}_{\\text{relu}}(\\textbf{Z}^1)\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "h_{11} & h_{12} & h_{13}\\\\\n",
    "h_{21} & h_{22} & h_{23}\\\\\n",
    "\\vdots & \\vdots & \\vdots \\\\\n",
    "h_{n1} & h_{n2} & h_{n3}\\\\\n",
    "\\end{bmatrix}\n",
    "= \\textbf{H}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "<span style='color:blue'>1. Define the relu activation</span><div></div>\n",
    "<span style='color:blue'>2. use `plot_activation_func` to confirm implementation</span><div></div>\n",
    "<span style='color:blue'>3. Use relu on `Z1` to create `H`</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(z: np.array) -> np.array:\n",
    "    # your code here\n",
    "    h = np.maximum(0,z)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_activation_func(f, name):\n",
    "    lin_x = np.linspace(-10,10,200)\n",
    "    h = f(lin_x)\n",
    "    plt.plot(lin_x, h)\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.title(f'{name} Activation Function')\n",
    "\n",
    "plot_activation_func(relu, name='RELU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "H = relu(Z1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is very similar to the first\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1 & h_{11} & h_{12} & h_{13}\\\\\n",
    "1 & h_{21} & h_{22} & h_{23}\\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "1 & h_{n1} & h_{n2} & h_{n3}\\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "b_{1}^2 & b_{2}^2 & b_{3}^2\\\\\n",
    "W_{11}^2 & W_{12}^2 & W_{13}^2\\\\\n",
    "W_{21}^2 & W_{22}^2 & W_{23}^2\\\\\n",
    "W_{31}^2 & W_{32}^2 & W_{33}^2\\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "z_{11}^2 & z_{12}^2 & z_{13}^2\\\\\n",
    "z_{21}^2 & z_{22}^2 & z_{23}^2\\\\\n",
    "\\vdots & \\vdots & \\vdots \\\\\n",
    "z_{n1}^2 & z_{n2}^2 & z_{n3}^2\\\\\n",
    "\\end{bmatrix}\n",
    "= \\textbf{Z}^2\n",
    "$$\n",
    "\n",
    "\n",
    "<span style='color:blue'>1. Augment `H` with ones to create `H_aug`</span><div></div>\n",
    "<span style='color:blue'>2. Combine `w2` and `b2` to create the output weight matric `W2`</span><div></div>\n",
    "<span style='color:blue'>3. Perform the matrix multiplication to produce `Z2`</span><div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "H_aug = add_ones_col(H)\n",
    "W2 = np.vstack((b2,w2))\n",
    "Z2 = np.matmul(H_aug, W2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we use the softmax activation on `Z2`. Now for each observation we have an output vector of length 3 which can be interpreted as a probability (they sum to 1).\n",
    "$$\n",
    "\\textit{a}_{\\text{softmax}}(\\textbf{Z}^2)\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "\\hat{y}_{11} & \\hat{y}_{12} & \\hat{y}_{13}\\\\\n",
    "\\hat{y}_{21} & \\hat{y}_{22} & \\hat{y}_{23}\\\\\n",
    "\\vdots & \\vdots & \\vdots \\\\\n",
    "\\hat{y}_{n1} & \\hat{y}_{n2} & \\hat{y}_{n3}\\\\\n",
    "\\end{bmatrix}\n",
    "= \\hat{\\textbf{Y}}\n",
    "$$\n",
    "\n",
    "<span style='color:blue'>1. Define softmax</span><div></div>\n",
    "<span style='color:blue'>2. Use `softmax` on `Z2` to create `Y_hat`</span><div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z: np.array) -> np.array:\n",
    "    '''\n",
    "    Input: z - 2D numpy array of logits \n",
    "           rows are observations, classes are columns \n",
    "    Returns: y_hat - 2D numpy array of probabilities\n",
    "             rows are observations, classes are columns \n",
    "    '''\n",
    "    # hint: be careful which axis you sum over, and set keepdims=True\n",
    "    # your code here\n",
    "    \n",
    "    y_hat = np.exp(z)/np.sum(np.exp(z),axis=1,keepdims=True)\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat = softmax(Z2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue'>Now let's see how accuract the model's predictions are! Use `np.argmax` to collapse the columns of `Y_hat` to create `y_hat`, a vector of class labels like the original `y` before one-hot encoding.</span><div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 96.67%\n"
     ]
    }
   ],
   "source": [
    "### edTest(test_acc) ###\n",
    "# your code here\n",
    "y_hat = np.argmax(Y_hat, axis=1)\n",
    "acc = sum(y == y_hat)/len(y)\n",
    "print(f'accuracy: {acc:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
